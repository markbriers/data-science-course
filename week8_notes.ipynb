{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week8-notes.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMvl0tiOaIpAs4tvQjekNkG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/markbriers/data-science-jupyter/blob/main/week8_notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLrbkBC9NgB2"
      },
      "source": [
        " # Modelling part 3 (Week 8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9WUKeYENpRx"
      },
      "source": [
        "Code at: https://github.com/markbriers/data-science-jupyter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDtdyAqfNrdb"
      },
      "source": [
        "## Recap - the story so far"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeDfHRh5Ntqs"
      },
      "source": [
        "Our goal is to follow a data science process (CRISP-DM) to deliver a successful business outcome.\n",
        "\n",
        "Our learning objectives are as follows:\n",
        "\n",
        "* Describe the six stages of a data processing pipeline (using CRISP-DM)\n",
        "\n",
        "* Demonstrate an understanding of the python programming language through the production of elementary data analysis programme\n",
        "\n",
        "* Analyse at least three different data sources by applying at least one python data processing library to extract and explore pertinent features\n",
        "\n",
        "* Be able to design a set of data requirements for a specified business problem\n",
        "\n",
        "* Describe and apply (using the python programming language) the main approaches to supervised learning for a given classification problem\n",
        "\n",
        "* Understand the use cases of Big Data technology (in particular Spark)\n",
        "\n",
        "* Produce a report including appropriate data visualisations covering the analysis of a business problem using a data science based approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5G8Tam5Nx6H"
      },
      "source": [
        "## Learning outcome\n",
        "\n",
        "* By the end of the lecture, you will be able to use the tensorflow library to estimate parameters of a binary classification model.\n",
        "\n",
        "* By the end of the lecture, you will be able to use the tensorflow library to estimate parameters of a deep neural network.\n",
        "\n",
        "* By the end of the lecture, you will have a high level understanding of Generative Adversarial Networks (GANs), and how they can be used to generate \"fake news\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kfHeB0xOPz2"
      },
      "source": [
        "# Bernoulli distribution and coin tossing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZifwgyAOVCI"
      },
      "source": [
        "Let's compute the following probabilities:\n",
        "* Tossing T with a fair coin\n",
        "* Tossing HH with a fair coin\n",
        "* Tossing HT with a fair coin\n",
        "* Tossing HTH with a fair coin\n",
        "* Tossing H with a biased coin ($p(head) = \\lambda = 0.1$)\n",
        "* Tossing HT with a biased coin ($p(head) = \\lambda = 0.1$)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn0vPwpZOYBM"
      },
      "source": [
        "Now we'll (informally) introduce the concept of a random variable, denoted $C$, where $C=0$ corresponds to coin landing on heads and $C=1$ corresponds to coin landing on tails. The probability of $C=1$ is equal to $\\lambda$. If $\\lambda=0.5$ then the coin is unbiased (and we're maximally uncertain about the outcome of a coin toss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S49kuyroOa29"
      },
      "source": [
        "We can say that $C$ follows a Bernoulli distribution, with *probability mass function* equal to the following expression:\n",
        "\\begin{equation}\n",
        "p(C|\\lambda) = \\lambda^{C}(1-\\lambda)^{1-C}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Anjj8-FGOdzT"
      },
      "source": [
        "## Logistic regression - binary classification (supervised learning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDK43Y6BOg_g"
      },
      "source": [
        "Consider the scenario where we wish to partition objects into two categories (e.g. spam or not spam, fraud or not fraud, positive sentiment or negative sentiment, face present or face not present, ...) given a set of attributes. The simplest (and widest used) model to achieve this is known as a Logistic Regression model. The Logistic Regression model \"squashes\" the output of a linear regression model, so that the resultant squashed output is between $0$ and $1$. This \"squashed\" output can be interpreted as a class probabaility (e.g. probability of spam or not spam). So what is the squashing function? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uk6wTn0JOjlB"
      },
      "source": [
        "### Sigmoid function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxM-mw__Omai"
      },
      "source": [
        "$sigm(\\eta)$ is known as the sigmoid function (also known as the _logistic_ or _logit_ function):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KNVAYYEOo4X"
      },
      "source": [
        "\\begin{equation}\n",
        "sigm(\\eta) = \\frac{1}{1+e^{-\\eta}} = \\frac{e^{\\eta}}{e^{\\eta}+1}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HdpBmF-Oreq"
      },
      "source": [
        "This function has the property that is \"squashes\" any input (from $-\\infty < \\eta < \\infty$) to a value between 0 and 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG8NF9M7OuXP"
      },
      "source": [
        "We can use the Bernouilli expression introduced above to model input data and (probabilistically) ascertain whether the data are from one class or another:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiaZX9QjOw6O"
      },
      "source": [
        "\\begin{equation}\n",
        "\\prod_{i=1}^{N} Ber(C_{i}|sigm(\\theta x_{i})) = \\prod_{i=1}^{N} \\left[\\frac{1}{1+e^{-\\theta x_{i}}} \\right]^{C_{i}} \\left[1-\\frac{1}{1+e^{-\\theta x_{i}}} \\right]^{1-C_{i}}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpecF5z2OzVB"
      },
      "source": [
        "So how do we estimate model parameters $\\theta$? What is the loss function?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRqvu_LIO15y"
      },
      "source": [
        "### Cross-entropy loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxIXxMsTO4kw"
      },
      "source": [
        "Let's introduce entropy: https://en.wikipedia.org/wiki/Entropy_(information_theory). Entropy can be considered to be a measure of uncertainty. For example, in the case of coin tossing, the value oof $\\lambda$ that maximises entropy is $\\lambda = 0.5$ - we are maximally uncertain about the outcome of the \"experiment\". We therefore want to chose a value of $\\theta$ (in the above model) that minimises *cross entropy loss*:\n",
        "\\begin{equation}\n",
        "c(\\theta) = -\\frac{1}{N}\\sum_{i=1}^{N} \\left[C_{i}log\\hat{C}_{i}+(1-C_{i})log(1-\\hat{C}_{i})\\right]\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75LA3C_pO7V5"
      },
      "source": [
        "where:\n",
        "\\begin{equation}\n",
        "\\hat{C}_{i} = \\frac{1}{1+e^{-\\theta x_{i}}}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VL_kMHlPO-WZ"
      },
      "source": [
        "In order to compute the optimal value of $\\theta$ that minimises the cross entropy loss, we use the chain rule (differentiation of composed functions) and gradient descent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXX1c8aYTAlG"
      },
      "source": [
        "### Tensorflow implementation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vUJBWSuTEje"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns \n",
        "import tensorflow as tf \n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7q9Yzr0jTJz3"
      },
      "source": [
        "The dataset basically consists of 7 columns:\n",
        "\n",
        "* price (the buying price of the car)\n",
        "* maint (the maintenance cost)\n",
        "* doors (number of doors)\n",
        "* persons (the seating capacity)\n",
        "* lug_capacity (the luggage capacity)\n",
        "* safety (how safe is the car)\n",
        "* output (the condition of the car)\n",
        "\n",
        "Given the first 6 columns, the task is to predict the value for the 7th column i.e. the output column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAF3OGHiTann",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "17138f26-b9a3-49bc-c2be-968b6e324991"
      },
      "source": [
        "cols = ['price', 'maint', 'doors', 'persons', 'lug_capacity', 'safety','output']\n",
        "cars = pd.read_csv('https://raw.githubusercontent.com/vortexeye/Car-Evaluation/master/car_evaluation.csv', names=cols, header=None)\n",
        "cars.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>maint</th>\n",
              "      <th>doors</th>\n",
              "      <th>persons</th>\n",
              "      <th>lug_capacity</th>\n",
              "      <th>safety</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>vhigh</td>\n",
              "      <td>vhigh</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>small</td>\n",
              "      <td>low</td>\n",
              "      <td>unacc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>vhigh</td>\n",
              "      <td>vhigh</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>small</td>\n",
              "      <td>med</td>\n",
              "      <td>unacc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>vhigh</td>\n",
              "      <td>vhigh</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>small</td>\n",
              "      <td>high</td>\n",
              "      <td>unacc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>vhigh</td>\n",
              "      <td>vhigh</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>med</td>\n",
              "      <td>low</td>\n",
              "      <td>unacc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>vhigh</td>\n",
              "      <td>vhigh</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>med</td>\n",
              "      <td>med</td>\n",
              "      <td>unacc</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   price  maint doors persons lug_capacity safety output\n",
              "0  vhigh  vhigh     2       2        small    low  unacc\n",
              "1  vhigh  vhigh     2       2        small    med  unacc\n",
              "2  vhigh  vhigh     2       2        small   high  unacc\n",
              "3  vhigh  vhigh     2       2          med    low  unacc\n",
              "4  vhigh  vhigh     2       2          med    med  unacc"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E30FLltNVN9S"
      },
      "source": [
        "### Brief exploratory analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdaDK4tjJDiK"
      },
      "source": [
        "Let's perform a brief exploratory analysis of the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "0zEuL2tSVaEf",
        "outputId": "d78f5699-bb3a-4d97-a6af-5cf1b9fdd90b"
      },
      "source": [
        "cars.output.value_counts().plot(kind='pie', autopct='%0.05f%%', colors=['lightblue', 'lightgreen', 'orange', 'pink'], explode=(0.05, 0.05, 0.05,0.05))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1363945610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7Fv-mCQVnmI"
      },
      "source": [
        "Let's convert the categorical values into numerical values (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6493ntKVqGz"
      },
      "source": [
        "price = pd.get_dummies(cars.price, prefix='price') #The get_dummies() function is used to convert categorical variable into dummy/indicator variables\n",
        "maint = pd.get_dummies(cars.maint, prefix='maint')\n",
        "\n",
        "doors = pd.get_dummies(cars.doors, prefix='doors')\n",
        "persons = pd.get_dummies(cars.persons, prefix='persons')\n",
        "\n",
        "lug_capacity = pd.get_dummies(cars.lug_capacity, prefix='lug_capacity')\n",
        "safety = pd.get_dummies(cars.safety, prefix='safety')\n",
        "\n",
        "labels = pd.get_dummies(cars.output, prefix='condition')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_etXvdh3JyO3"
      },
      "source": [
        "Now concatonate the two data frames (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "lG_3PYIYVtoQ",
        "outputId": "0f8811d9-b5a4-492e-82bb-1838123c4ad6"
      },
      "source": [
        "X = pd.concat([price, maint, doors, persons, lug_capacity, safety] , axis=1)\n",
        "X.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price_high</th>\n",
              "      <th>price_low</th>\n",
              "      <th>price_med</th>\n",
              "      <th>price_vhigh</th>\n",
              "      <th>maint_high</th>\n",
              "      <th>maint_low</th>\n",
              "      <th>maint_med</th>\n",
              "      <th>maint_vhigh</th>\n",
              "      <th>doors_2</th>\n",
              "      <th>doors_3</th>\n",
              "      <th>doors_4</th>\n",
              "      <th>doors_5more</th>\n",
              "      <th>persons_2</th>\n",
              "      <th>persons_4</th>\n",
              "      <th>persons_more</th>\n",
              "      <th>lug_capacity_big</th>\n",
              "      <th>lug_capacity_med</th>\n",
              "      <th>lug_capacity_small</th>\n",
              "      <th>safety_high</th>\n",
              "      <th>safety_low</th>\n",
              "      <th>safety_med</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   price_high  price_low  price_med  ...  safety_high  safety_low  safety_med\n",
              "0           0          0          0  ...            0           1           0\n",
              "1           0          0          0  ...            0           0           1\n",
              "2           0          0          0  ...            1           0           0\n",
              "3           0          0          0  ...            0           1           0\n",
              "4           0          0          0  ...            0           0           1\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwLMM5WxPKhP"
      },
      "source": [
        "The labels dataframe corresponds to the output category (i.e. the condition of the vehicle):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "tR10u7IXVwsW",
        "outputId": "aef0118a-8ea3-442a-ee49-63df0c5f9d69"
      },
      "source": [
        "labels.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>condition_acc</th>\n",
              "      <th>condition_good</th>\n",
              "      <th>condition_unacc</th>\n",
              "      <th>condition_vgood</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   condition_acc  condition_good  condition_unacc  condition_vgood\n",
              "0              0               0                1                0\n",
              "1              0               0                1                0\n",
              "2              0               0                1                0\n",
              "3              0               0                1                0\n",
              "4              0               0                1                0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW4WxktAVzQP"
      },
      "source": [
        "y = labels.values"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liZRIICoV1hE"
      },
      "source": [
        "We'll randomly split the data into training and test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voUr4rKWV4km"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj8SJT5mV35H"
      },
      "source": [
        "And create the model as layers in tensorflow:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ5VPs2GV9kK"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Activation,Dropout\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3ySC9EuV_oz"
      },
      "source": [
        "input_layer = Input(shape=(X.shape[1],))\n",
        "output = Dense(y.shape[1], activation='softmax')(input_layer)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['acc'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5YmJGcfWDfB"
      },
      "source": [
        "The softmax activation function acts as a generalisation of the sigmoid function in logistic regression, to allow for multi-class classification problems (i.e. it extends binary classification) - see https://www.kdnuggets.com/2016/07/softmax-regression-related-logistic-regression.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zcpn2vUWGE2",
        "outputId": "9efc1496-82f7-472b-9d7e-d9ba17684354"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 21)]              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 88        \n",
            "=================================================================\n",
            "Total params: 88\n",
            "Trainable params: 88\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPRuxgg7PcaW"
      },
      "source": [
        "Now we can fit the model (i.e. estimate the parameters):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfjXAVMlWI0b",
        "outputId": "e955357d-8228-46ae-b196-23f1a79d1535"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=8, epochs=50, verbose=1, validation_split=0.2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "139/139 [==============================] - 1s 3ms/step - loss: 1.3379 - acc: 0.3924 - val_loss: 0.9411 - val_acc: 0.6570\n",
            "Epoch 2/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.8254 - acc: 0.7237 - val_loss: 0.8297 - val_acc: 0.6787\n",
            "Epoch 3/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.7189 - acc: 0.7477 - val_loss: 0.7780 - val_acc: 0.6679\n",
            "Epoch 4/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.6592 - acc: 0.7414 - val_loss: 0.7412 - val_acc: 0.6751\n",
            "Epoch 5/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.6408 - acc: 0.7369 - val_loss: 0.7131 - val_acc: 0.6823\n",
            "Epoch 6/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.5840 - acc: 0.7513 - val_loss: 0.6889 - val_acc: 0.6968\n",
            "Epoch 7/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.5348 - acc: 0.7739 - val_loss: 0.6688 - val_acc: 0.7148\n",
            "Epoch 8/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.5326 - acc: 0.7701 - val_loss: 0.6522 - val_acc: 0.7148\n",
            "Epoch 9/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.5369 - acc: 0.7852 - val_loss: 0.6374 - val_acc: 0.7473\n",
            "Epoch 10/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.5074 - acc: 0.8055 - val_loss: 0.6239 - val_acc: 0.7653\n",
            "Epoch 11/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.4957 - acc: 0.8323 - val_loss: 0.6116 - val_acc: 0.7762\n",
            "Epoch 12/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.5143 - acc: 0.8206 - val_loss: 0.6013 - val_acc: 0.7690\n",
            "Epoch 13/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.4824 - acc: 0.8334 - val_loss: 0.5906 - val_acc: 0.7834\n",
            "Epoch 14/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.4975 - acc: 0.8379 - val_loss: 0.5816 - val_acc: 0.7798\n",
            "Epoch 15/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.4663 - acc: 0.8378 - val_loss: 0.5730 - val_acc: 0.7870\n",
            "Epoch 16/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.4630 - acc: 0.8441 - val_loss: 0.5646 - val_acc: 0.7834\n",
            "Epoch 17/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.4571 - acc: 0.8408 - val_loss: 0.5565 - val_acc: 0.7978\n",
            "Epoch 18/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.4635 - acc: 0.8463 - val_loss: 0.5499 - val_acc: 0.7906\n",
            "Epoch 19/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.4651 - acc: 0.8402 - val_loss: 0.5426 - val_acc: 0.7978\n",
            "Epoch 20/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.4458 - acc: 0.8494 - val_loss: 0.5359 - val_acc: 0.8123\n",
            "Epoch 21/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.4172 - acc: 0.8541 - val_loss: 0.5299 - val_acc: 0.8087\n",
            "Epoch 22/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.4007 - acc: 0.8731 - val_loss: 0.5239 - val_acc: 0.8087\n",
            "Epoch 23/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.4103 - acc: 0.8645 - val_loss: 0.5179 - val_acc: 0.8051\n",
            "Epoch 24/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.4081 - acc: 0.8641 - val_loss: 0.5129 - val_acc: 0.8051\n",
            "Epoch 25/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.4377 - acc: 0.8400 - val_loss: 0.5079 - val_acc: 0.8195\n",
            "Epoch 26/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.4026 - acc: 0.8714 - val_loss: 0.5031 - val_acc: 0.8231\n",
            "Epoch 27/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.3976 - acc: 0.8573 - val_loss: 0.4984 - val_acc: 0.8231\n",
            "Epoch 28/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.3931 - acc: 0.8590 - val_loss: 0.4942 - val_acc: 0.8231\n",
            "Epoch 29/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.3793 - acc: 0.8741 - val_loss: 0.4900 - val_acc: 0.8231\n",
            "Epoch 30/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.4017 - acc: 0.8641 - val_loss: 0.4862 - val_acc: 0.8231\n",
            "Epoch 31/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.4072 - acc: 0.8444 - val_loss: 0.4821 - val_acc: 0.8231\n",
            "Epoch 32/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.3736 - acc: 0.8687 - val_loss: 0.4787 - val_acc: 0.8231\n",
            "Epoch 33/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.3768 - acc: 0.8661 - val_loss: 0.4751 - val_acc: 0.8231\n",
            "Epoch 34/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.3859 - acc: 0.8510 - val_loss: 0.4717 - val_acc: 0.8231\n",
            "Epoch 35/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.3722 - acc: 0.8576 - val_loss: 0.4682 - val_acc: 0.8231\n",
            "Epoch 36/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.3625 - acc: 0.8643 - val_loss: 0.4650 - val_acc: 0.8267\n",
            "Epoch 37/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.3729 - acc: 0.8656 - val_loss: 0.4620 - val_acc: 0.8231\n",
            "Epoch 38/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.3599 - acc: 0.8600 - val_loss: 0.4591 - val_acc: 0.8231\n",
            "Epoch 39/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.3642 - acc: 0.8593 - val_loss: 0.4562 - val_acc: 0.8267\n",
            "Epoch 40/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.3638 - acc: 0.8632 - val_loss: 0.4535 - val_acc: 0.8267\n",
            "Epoch 41/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.3685 - acc: 0.8575 - val_loss: 0.4508 - val_acc: 0.8267\n",
            "Epoch 42/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.3706 - acc: 0.8713 - val_loss: 0.4482 - val_acc: 0.8267\n",
            "Epoch 43/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.3434 - acc: 0.8689 - val_loss: 0.4458 - val_acc: 0.8267\n",
            "Epoch 44/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.3681 - acc: 0.8437 - val_loss: 0.4433 - val_acc: 0.8267\n",
            "Epoch 45/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.3482 - acc: 0.8527 - val_loss: 0.4410 - val_acc: 0.8267\n",
            "Epoch 46/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.3564 - acc: 0.8537 - val_loss: 0.4387 - val_acc: 0.8267\n",
            "Epoch 47/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.3361 - acc: 0.8738 - val_loss: 0.4364 - val_acc: 0.8303\n",
            "Epoch 48/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.3389 - acc: 0.8678 - val_loss: 0.4342 - val_acc: 0.8303\n",
            "Epoch 49/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.3428 - acc: 0.8565 - val_loss: 0.4325 - val_acc: 0.8303\n",
            "Epoch 50/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.3503 - acc: 0.8568 - val_loss: 0.4302 - val_acc: 0.8303\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "790zNksLPgV_"
      },
      "source": [
        "And evaluate how well the model has performed on the held-out test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHg6PGlAWNHb",
        "outputId": "ccf579b4-b128-4529-fe0a-2fa5cbd59f25"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "\n",
        "print(\"Test Score:\", score[0])\n",
        "print(\"Test Accuracy:\", score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11/11 [==============================] - 0s 1ms/step - loss: 0.3828 - acc: 0.8497\n",
            "Test Score: 0.38277667760849\n",
            "Test Accuracy: 0.849711000919342\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDUaW9B3WTLN"
      },
      "source": [
        "## Deep Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TlumoIPWVr4"
      },
      "source": [
        "Finally, we can make our model \"Deep\" (i.e. we can create a deep neural network) by adding additional layers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXQx1p0oWS-a"
      },
      "source": [
        "input_layer = Input(shape=(X.shape[1],))\n",
        "dense_layer_1 = Dense(15, activation='relu')(input_layer)\n",
        "dense_layer_2 = Dense(10, activation='relu')(dense_layer_1)\n",
        "dense_layer_3 = Dense(20, activation='relu')(dense_layer_2)\n",
        "output = Dense(y.shape[1], activation='softmax')(dense_layer_3)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKLr2lCNWaAY"
      },
      "source": [
        "Here we use a relu (rectified linear unit) activation function: https://www.tinymind.com/learn/terms/relu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hH__sJJ6Wb11",
        "outputId": "b8066904-2369-4f93-a76b-1dd3709d6dac"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 21)]              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 15)                330       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                160       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 4)                 84        \n",
            "=================================================================\n",
            "Total params: 794\n",
            "Trainable params: 794\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MWdBSHmWeg9",
        "outputId": "308dc306-4f54-409e-bd67-abec21d7c9cf"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=8, epochs=50, verbose=1, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "139/139 [==============================] - 1s 3ms/step - loss: 1.0615 - acc: 0.7142 - val_loss: 0.8876 - val_acc: 0.6498\n",
            "Epoch 2/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.7216 - acc: 0.7251 - val_loss: 0.6928 - val_acc: 0.6498\n",
            "Epoch 3/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.5149 - acc: 0.7491 - val_loss: 0.5129 - val_acc: 0.7617\n",
            "Epoch 4/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.3965 - acc: 0.8296 - val_loss: 0.4182 - val_acc: 0.8159\n",
            "Epoch 5/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.2844 - acc: 0.8903 - val_loss: 0.3337 - val_acc: 0.8664\n",
            "Epoch 6/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.2358 - acc: 0.9124 - val_loss: 0.2880 - val_acc: 0.8773\n",
            "Epoch 7/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.2078 - acc: 0.9032 - val_loss: 0.2575 - val_acc: 0.8845\n",
            "Epoch 8/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.1677 - acc: 0.9430 - val_loss: 0.2176 - val_acc: 0.9097\n",
            "Epoch 9/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.1438 - acc: 0.9501 - val_loss: 0.2065 - val_acc: 0.9097\n",
            "Epoch 10/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.1192 - acc: 0.9670 - val_loss: 0.1767 - val_acc: 0.9495\n",
            "Epoch 11/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.1062 - acc: 0.9722 - val_loss: 0.1581 - val_acc: 0.9531\n",
            "Epoch 12/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.0907 - acc: 0.9697 - val_loss: 0.1612 - val_acc: 0.9495\n",
            "Epoch 13/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.0837 - acc: 0.9776 - val_loss: 0.1315 - val_acc: 0.9639\n",
            "Epoch 14/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.0870 - acc: 0.9768 - val_loss: 0.1208 - val_acc: 0.9675\n",
            "Epoch 15/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.0720 - acc: 0.9806 - val_loss: 0.1125 - val_acc: 0.9603\n",
            "Epoch 16/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.0547 - acc: 0.9909 - val_loss: 0.1201 - val_acc: 0.9567\n",
            "Epoch 17/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.0529 - acc: 0.9900 - val_loss: 0.0982 - val_acc: 0.9603\n",
            "Epoch 18/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.0469 - acc: 0.9927 - val_loss: 0.0932 - val_acc: 0.9675\n",
            "Epoch 19/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.0407 - acc: 0.9915 - val_loss: 0.0974 - val_acc: 0.9567\n",
            "Epoch 20/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.0319 - acc: 0.9923 - val_loss: 0.0955 - val_acc: 0.9639\n",
            "Epoch 21/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.0389 - acc: 0.9889 - val_loss: 0.0799 - val_acc: 0.9603\n",
            "Epoch 22/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.0282 - acc: 0.9989 - val_loss: 0.0840 - val_acc: 0.9639\n",
            "Epoch 23/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.0277 - acc: 0.9950 - val_loss: 0.0925 - val_acc: 0.9639\n",
            "Epoch 24/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.0245 - acc: 0.9975 - val_loss: 0.0644 - val_acc: 0.9747\n",
            "Epoch 25/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.0176 - acc: 0.9971 - val_loss: 0.0821 - val_acc: 0.9639\n",
            "Epoch 26/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.0181 - acc: 0.9981 - val_loss: 0.0708 - val_acc: 0.9675\n",
            "Epoch 27/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.0152 - acc: 0.9973 - val_loss: 0.0581 - val_acc: 0.9747\n",
            "Epoch 28/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.0200 - acc: 0.9960 - val_loss: 0.0550 - val_acc: 0.9747\n",
            "Epoch 29/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.0132 - acc: 0.9999 - val_loss: 0.0690 - val_acc: 0.9747\n",
            "Epoch 30/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.0095 - acc: 0.9993 - val_loss: 0.0543 - val_acc: 0.9747\n",
            "Epoch 31/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.0572 - val_acc: 0.9711\n",
            "Epoch 32/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.0078 - acc: 0.9997 - val_loss: 0.0605 - val_acc: 0.9747\n",
            "Epoch 33/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.0114 - acc: 0.9983 - val_loss: 0.0460 - val_acc: 0.9856\n",
            "Epoch 34/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0451 - val_acc: 0.9747\n",
            "Epoch 35/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0508 - val_acc: 0.9711\n",
            "Epoch 36/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0565 - val_acc: 0.9711\n",
            "Epoch 37/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0678 - val_acc: 0.9747\n",
            "Epoch 38/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0437 - val_acc: 0.9819\n",
            "Epoch 39/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0479 - val_acc: 0.9783\n",
            "Epoch 40/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0455 - val_acc: 0.9819\n",
            "Epoch 41/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0508 - val_acc: 0.9819\n",
            "Epoch 42/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0431 - val_acc: 0.9783\n",
            "Epoch 43/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0480 - val_acc: 0.9783\n",
            "Epoch 44/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0452 - val_acc: 0.9819\n",
            "Epoch 45/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0390 - val_acc: 0.9819\n",
            "Epoch 46/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0372 - val_acc: 0.9819\n",
            "Epoch 47/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0534 - val_acc: 0.9711\n",
            "Epoch 48/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0431 - val_acc: 0.9783\n",
            "Epoch 49/50\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0284 - val_acc: 0.9856\n",
            "Epoch 50/50\n",
            "139/139 [==============================] - 0s 1ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0329 - val_acc: 0.9856\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2VpFF3HPm6Z"
      },
      "source": [
        "Notice the difference (improvement) in classification performance when we added more layers into the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HydrpJiMWir9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1ac6a75-2ccf-48b1-c006-6734e85ad11f"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "\n",
        "print(\"Test Score:\", score[0])\n",
        "print(\"Test Accuracy:\", score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11/11 [==============================] - 0s 1ms/step - loss: 0.0248 - acc: 0.9942\n",
            "Test Score: 0.02476133219897747\n",
            "Test Accuracy: 0.9942196607589722\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEn_R3M_WiNx"
      },
      "source": [
        "The art and science of deep neural networks involves designing appropriately large networks (with billions of parameters), defining the \"activation\" functions, and using specific \"bells and whistles\" to optimise performance. A further analysis of deep neural networks is beyond the scope of this module. The interested reader is referred to https://www.coursera.org/learn/neural-networks-deep-learning for an in-depth exposition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYmUosIBSQUG"
      },
      "source": [
        "## Generative Adversarial Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kez1yuuRPtVp"
      },
      "source": [
        "The user of Generative Adversarial Networks is becoming widespread, underpinning lots of misinformation on the internet. The ability to use a pair of deep neural networks in order to produce realistic, but deceptive, information, is likely to be societally disruptive in the coming years. A recent example of a \"Deepfake\" is in the video below (is this real or fake?!):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "UMZ_vgfwR6BD",
        "outputId": "715435aa-6123-4d94-a446-5252bce11b9c"
      },
      "source": [
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('iyiOVUbsPcM')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"400\"\n",
              "            height=\"300\"\n",
              "            src=\"https://www.youtube.com/embed/iyiOVUbsPcM\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.YouTubeVideo at 0x7f9d70302350>"
            ],
            "image/jpeg": "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\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb80sY89Ub9M"
      },
      "source": [
        "Here's another example, this time in text generation: https://deepai.org/machine-learning-model/text-generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAQh1_iMTRv_"
      },
      "source": [
        "A GAN uses two deep neural networks in order to build up a statistical representation of a data set, which can be used to generate synthetic data. A detailed methodological review of GANs is beyond the scope of this module. However, those interested in the detail should read: https://machinelearningmastery.com/what-are-generative-adversarial-networks-gans/ for example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVSA8rWLPEFi"
      },
      "source": [
        "***\n",
        "Mandatory exercises:\n",
        "\n",
        "- [ ] Carefully read the material above, and ask questions over email.\n",
        "- [ ] Replicate all of the code in this notebook."
      ]
    }
  ]
}